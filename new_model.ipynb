{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nb_model.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = pd.read_csv('Training_new.csv').dropna(axis=1)\n",
    "\n",
    "# Separate features and labels\n",
    "X = dataset.drop('prognosis', axis=1)\n",
    "y = dataset['prognosis']\n",
    "encoder = LabelEncoder()\n",
    "dataset[\"prognosis\"] = encoder.fit_transform(dataset[\"prognosis\"])\n",
    "\n",
    "# Splitting the data into training and testing sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Limiting the size of the training data to avoid overfitting\n",
    "X_train_small, _, y_train_small, _ = train_test_split(X_train, y_train, test_size=0.5, random_state=42)\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(X_train_small, y_train_small)\n",
    "rf_predictions_train = rf_classifier.predict(X_train)\n",
    "rf_cm_train = confusion_matrix(y_train, rf_predictions_train)\n",
    "\n",
    "# Save the Random Forest model\n",
    "joblib.dump(rf_classifier, 'rf_model.pkl')\n",
    "\n",
    "# SVM Classifier\n",
    "svm_classifier = SVC()\n",
    "svm_classifier.fit(X_train_small, y_train_small)\n",
    "svm_predictions_train = svm_classifier.predict(X_train)\n",
    "svm_cm_train = confusion_matrix(y_train, svm_predictions_train)\n",
    "\n",
    "# Save the SVM model\n",
    "joblib.dump(svm_classifier, 'svm_model.pkl')\n",
    "\n",
    "# Gaussian Naive Bayes Classifier\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train_small, y_train_small)\n",
    "nb_predictions_train = nb_classifier.predict(X_train)\n",
    "nb_cm_train = confusion_matrix(y_train, nb_predictions_train)\n",
    "\n",
    "# Save the Naive Bayes model\n",
    "joblib.dump(nb_classifier, 'nb_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy for each model on the training data\n",
    "rf_accuracy_train = accuracy_score(y_train, rf_predictions_train)\n",
    "svm_accuracy_train = accuracy_score(y_train, svm_predictions_train)\n",
    "nb_accuracy_train = accuracy_score(y_train, nb_predictions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Confusion Matrix (Training):\n",
      "True Positive: 5\n",
      "True Negative: 0\n",
      "False Positive: 0\n",
      "False Negative: 0\n",
      "\n",
      "SVM Confusion Matrix (Training):\n",
      "True Positive: 4\n",
      "True Negative: 0\n",
      "False Positive: 0\n",
      "False Negative: 0\n",
      "\n",
      "Gaussian Naive Bayes Confusion Matrix (Training):\n",
      "True Positive: 5\n",
      "True Negative: 0\n",
      "False Positive: 0\n",
      "False Negative: 0\n"
     ]
    }
   ],
   "source": [
    "# Display confusion matrix for each model in 2x2 format\n",
    "print(\"Random Forest Confusion Matrix (Training):\")\n",
    "print(\"True Positive:\", rf_cm_train[1, 1])\n",
    "print(\"True Negative:\", rf_cm_train[0, 0])\n",
    "print(\"False Positive:\", rf_cm_train[0, 1])\n",
    "print(\"False Negative:\", rf_cm_train[1, 0])\n",
    "\n",
    "print(\"\\nSVM Confusion Matrix (Training):\")\n",
    "print(\"True Positive:\", svm_cm_train[1, 1])\n",
    "print(\"True Negative:\", svm_cm_train[0, 0])\n",
    "print(\"False Positive:\", svm_cm_train[0, 1])\n",
    "print(\"False Negative:\", svm_cm_train[1, 0])\n",
    "\n",
    "print(\"\\nGaussian Naive Bayes Confusion Matrix (Training):\")\n",
    "print(\"True Positive:\", nb_cm_train[1, 1])\n",
    "print(\"True Negative:\", nb_cm_train[0, 0])\n",
    "print(\"False Positive:\", nb_cm_train[0, 1])\n",
    "print(\"False Negative:\", nb_cm_train[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Accuracy (Training): 0.9510869565217391\n",
      "SVM Accuracy (Training): 0.8967391304347826\n",
      "Gaussian Naive Bayes Accuracy (Training): 0.9510869565217391\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy for each model\n",
    "print(\"\\nRandom Forest Accuracy (Training):\", rf_accuracy_train)\n",
    "print(\"SVM Accuracy (Training):\", svm_accuracy_train)\n",
    "print(\"Gaussian Naive Bayes Accuracy (Training):\", nb_accuracy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Confusion Matrix (Training):\n",
      "True Positive: 175, False Positive: 9, False Negative: 9, True Negative: -9\n",
      "\n",
      "SVM Confusion Matrix (Training):\n",
      "True Positive: 165, False Positive: 19, False Negative: 19, True Negative: -19\n",
      "\n",
      "Gaussian Naive Bayes Confusion Matrix (Training):\n",
      "True Positive: 175, False Positive: 9, False Negative: 9, True Negative: -9\n"
     ]
    }
   ],
   "source": [
    "# Define a function to convert multi-class confusion matrix to 2x2 confusion matrix\n",
    "def multiclass_to_2x2_confusion_matrix(cm):\n",
    "    # Sum of diagonal elements represents TP\n",
    "    TP = cm.diagonal().sum()\n",
    "    \n",
    "    # Sum of all elements in the confusion matrix represents the total\n",
    "    total = cm.sum()\n",
    "    \n",
    "    # False Positive (FP) is the sum of all elements in the predicted column excluding TP\n",
    "    FP = cm.sum(axis=0).sum() - TP\n",
    "    \n",
    "    # False Negative (FN) is the sum of all elements in the actual row excluding TP\n",
    "    FN = cm.sum(axis=1).sum() - TP\n",
    "    \n",
    "    # True Negative (TN) is the total minus TP, FP, and FN\n",
    "    TN = total - TP - FP - FN\n",
    "    \n",
    "    # Return 2x2 confusion matrix\n",
    "    return TP, FP, FN, TN\n",
    "\n",
    "# Convert each multi-class confusion matrix to 2x2 confusion matrix\n",
    "rf_TP, rf_FP, rf_FN, rf_TN = multiclass_to_2x2_confusion_matrix(rf_cm_train)\n",
    "svm_TP, svm_FP, svm_FN, svm_TN = multiclass_to_2x2_confusion_matrix(svm_cm_train)\n",
    "nb_TP, nb_FP, nb_FN, nb_TN = multiclass_to_2x2_confusion_matrix(nb_cm_train)\n",
    "\n",
    "# Print 2x2 confusion matrices\n",
    "print(\"Random Forest Confusion Matrix (Training):\")\n",
    "print(f\"True Positive: {rf_TP}, False Positive: {rf_FP}, False Negative: {rf_FN}, True Negative: {rf_TN}\")\n",
    "\n",
    "print(\"\\nSVM Confusion Matrix (Training):\")\n",
    "print(f\"True Positive: {svm_TP}, False Positive: {svm_FP}, False Negative: {svm_FN}, True Negative: {svm_TN}\")\n",
    "\n",
    "print(\"\\nGaussian Naive Bayes Confusion Matrix (Training):\")\n",
    "print(f\"True Positive: {nb_TP}, False Positive: {nb_FP}, False Negative: {nb_FN}, True Negative: {nb_TN}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "\n",
    "# Load the saved models\n",
    "rf_model = joblib.load('rf_model.pkl')\n",
    "svm_model = joblib.load('svm_model.pkl')\n",
    "nb_model = joblib.load('nb_model.pkl')\n",
    "\n",
    "# Define label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y.unique())\n",
    "symptoms = X.columns.values\n",
    "prediction_classes = encoder.classes_\n",
    "symptom_index = {}\n",
    "for index, value in enumerate(symptoms):\n",
    "    symptom = \" \".join([i.capitalize() for i in value.split(\"_\")])\n",
    "    symptom_index[symptom] = index\n",
    "data_dict = {\n",
    "    \"symptom_index\": symptom_index,\n",
    "    \"predictions_classes\": prediction_classes\n",
    "}\n",
    "\n",
    "\n",
    "def predict_disease(symptoms):\n",
    "    input_data = [0] * len(data_dict[\"symptom_index\"])  # Initialize input_data with correct length\n",
    "    for symptom in symptoms:\n",
    "        index = data_dict[\"symptom_index\"].get(symptom.capitalize())\n",
    "        if index is not None:\n",
    "            input_data[index] = 1\n",
    "\n",
    "    input_data = np.array(input_data).reshape(1, -1)\n",
    "\n",
    "    # Predictions from models\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        rf_prediction = rf_model.predict(input_data)\n",
    "        nb_prediction = nb_model.predict(input_data)\n",
    "        svm_prediction = svm_model.predict(input_data)\n",
    "\n",
    "    # Convert predictions to numeric labels\n",
    "    rf_prediction_label = label_encoder.transform(rf_prediction)[0]\n",
    "    nb_prediction_label = label_encoder.transform(nb_prediction)[0]\n",
    "    svm_prediction_label = label_encoder.transform(svm_prediction)[0]\n",
    "\n",
    "    # Calculate majority prediction\n",
    "    predictions = [rf_prediction_label, nb_prediction_label, svm_prediction_label]\n",
    "    if len(set(predictions)) == 1:\n",
    "        final_prediction = predictions[0]  # All predictions are the same\n",
    "    else:\n",
    "        final_prediction = mode(predictions)[0][0]\n",
    "\n",
    "    # Decode prediction label to disease name\n",
    "    final_prediction = label_encoder.inverse_transform([final_prediction])[0]\n",
    "    \n",
    "    output = {\n",
    "        \"Random Forest\": label_encoder.inverse_transform([rf_prediction_label])[0],\n",
    "        \"SVM\": label_encoder.inverse_transform([svm_prediction_label])[0],\n",
    "        \"Gaussian Naive Bayes\": label_encoder.inverse_transform([nb_prediction_label])[0],\n",
    "        \"Final Prediction\": final_prediction\n",
    "    }\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Prediction: Paralysis (brain hemorrhage)\n",
      "SVM Prediction: Paralysis (brain hemorrhage)\n",
      "Gaussian Naive Bayes Prediction: Paralysis (brain hemorrhage)\n",
      "Final Prediction Prediction: Paralysis (brain hemorrhage)\n"
     ]
    }
   ],
   "source": [
    "# Define symptoms\n",
    "test_symptoms = [\"continuous_sneezing\", \"fatigue\", \"cough\", \"high_fever\", \"headache\"]\n",
    "\n",
    "# Call predict_disease function\n",
    "predictions = predict_disease(test_symptoms)\n",
    "\n",
    "# Print the predictions\n",
    "for model, disease in predictions.items():\n",
    "    print(f\"{model} Prediction:\", disease)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
